{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9736114,"sourceType":"datasetVersion","datasetId":5958822}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Limitation(s) of sklearn’s non-negative matrix factorization library**\nThose are the questions to answer:\n\n1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]\n\nMake sure that your notebook includes the following:\n\nuse's sklearn's non-negative matrix factorization\n\nnotebook shows the RMSE with an analysis of what that RMSE means\n\n2. Discuss the results and why they did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]","metadata":{}},{"cell_type":"markdown","source":"# **Question 1**","metadata":{}},{"cell_type":"code","source":"# Let's import the libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import make_pipeline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import floor\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom wordcloud import WordCloud\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom collections import namedtuple\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import coo_matrix, csr_matrix\nfrom scipy.spatial.distance import jaccard, cosine \nfrom pytest import approx\n\n# data\nrep=\"/kaggle/input/ratings\"\nMV_users = pd.read_csv(rep+'/users.csv')\nMV_movies = pd.read_csv(rep+'/movies.csv')\ntrain = pd.read_csv(rep+'/train.csv')\ntest = pd.read_csv(rep+'/test.csv')\nData = namedtuple('Data', ['users','movies','train','test'])\ndata = Data(MV_users, MV_movies, train, test)\n\n#print(data.train)\n# transform the matrix in a pivot table\npivot = data.train.pivot(index='uID', columns='mID', values='rating').fillna(0)\nn = len(data.train['rating'].unique())\nnmf = NMF(n_components=n, random_state=42)\nW = nmf.fit_transform(pivot)\nH = nmf.components_ \nWH = np.dot(W, H)\n\npreds = pd.DataFrame(WH, index=pivot.index, columns=pivot.columns)\n#print(preds.shape)\n\ny_true=pivot.values.flatten()\ny_pred=WH.flatten()\nidx=np.nonzero(y_true)\nerr=y_true[idx]-y_pred[idx]\nrmse=np.sqrt(sum(np.power(err,2))/len(err))\n\nprint(\"RMSE is: \",rmse)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T14:39:42.494978Z","iopub.execute_input":"2024-10-27T14:39:42.495469Z","iopub.status.idle":"2024-10-27T14:39:50.713695Z","shell.execute_reply.started":"2024-10-27T14:39:42.495428Z","shell.execute_reply":"2024-10-27T14:39:50.712510Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"RMSE is:  2.968076162331461\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The RMSE is huge, which indicates that NMF is not ideal to predict the user ratings. The RMSE obtained with the simple baseline or similarity-based methods in Module 3 is around 1, so NMF performs worse compared to those methods.","metadata":{}},{"cell_type":"markdown","source":"# **Question 2**","metadata":{}},{"cell_type":"markdown","source":"* Explanation for poor performance:\n* * NMF heavily depends on the size of data; since in the case of user ratings, matrices are sparse and have many empty values, which compromise its accuracy drastically\n* * Since NMF assumes a linear impact from the latent factors, if the latent factors have non-linear impacts or there are too many latent factors, whcih renders it difficult for the NMF model to interprete, the model will work poorly\n\n\n* Improvement\n* * We can fill in the sparse matrices with some approximation to avoid having a huge ammount of missing data\n* * We can try to combine the similarity method with the NMF to make up for its short-comings\n* * Last but not least, we can work on the data, to see if we can provide more meaningful features and adapt the data to NMF","metadata":{}}]}