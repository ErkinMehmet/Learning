{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# step 1: create an imbalanced binary classification dataset\nX,y=make_classification(n_samples=1000,n_features=10,n_informative=2,n_redundant=8,\n                       weights=[0.9,0.1],flip_y=0,random_state=42)\nnp.unique(y,return_counts=True)\n\n# Split the dataset into training and test sets\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,stratify=y,random_state=42)\n\n# Define the model hyperparams\nparams={\n    \"solver\":\"lbfgs\",\n    \"max_iter\":1000,\n    \"multi_class\":\"auto\",\n    \"random_state\":8888,\n}\n\n# Train the model\nlr=LogisticRegression(**params)\nlr.fit(X_train,y_train)\ny_pred=lr(X_test)\nreport=classification_report(y_test,y_pred)\nprint(report) # precision, recall, F1, support\n\nreport_dict=classification_report(y_test,y_pred,output_dict=True)\nprint(report_dict)\n\n# Use MLFlow to log the experiment\nimport mlflow\nmlflow.set_experiment(\"First Experiment\")\nmlflow.set_tracking_url(\"http://127.0.0.1:5000\") # the localhost if MLFlow is run on local\nwith mlflow.start_run():\n    mlflow.log_params(params)\n    mlflow.log_metrics({\n        'accuracy'=report_dict['accuracy'],\n        'recall_class_0':report_dict['0']['recall'],\n        'recall_class_1':report_dict['1']['recall'],\n        'f1_score_macro':report_dict['macro avg']['f1-score']\n    })\n    mlflow.sklearn.log_model(lr,\"LR_1\") # for logistic regression\n\n# The in the list of experiments, we will see the \"First Element\" in the user interface!\n# Inside the link, we will see all the parameters, the model, the metrics, etc.\n# Under the artifacts section, we can see the model.pkl, so that we can package or download et deploy it via Docker later\n# conda.yaml, python_env.yaml, requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Experiment 2\nxgb_clf=XGBClassifier(use_label_encoder=False,eval_metric='logloss')\nxgb_clf.fit(X_train,y_train)\ny_pred_xgb=xgb_clf.predict(X_test)\nreport=classification_report(y_test,Y_pred_xgb)\n\n# similarly, we can make Experiment 3 & 4, etc.\n\n# create a new dataset\nfrom imblearn.combine import SMOTETomek\nsmt=SMOTETomek(random_state=42)\nX_train_res,y_train_res=smt.fit_resample(X_train,y_train)\nnp.unique(y_train_res,return_counts=True)\n\n# we can create a list of models\nmodels=[\n    (\n        \"Logistic Regression\",\n        {C=1,solver='liblinear'}\n        LogisticRegression(),\n        (X_train,y_train),\n        (X_test,y_test)\n    ),\n    (\n        \"Random Forest\",\n        {n_estimators=30,max_depth=3},\n        RandomForestClassifier(),\n        (X_train,y_train),\n        (X_test,y_test)\n    ),\n    (\n        \"XGBClassifier\",\n        {use_label_encoder=False,eval_metric='logloss'},\n        XGBClassifier(),\n        (X_train,y_train),\n        (X_test,y_test)\n    ),\n    (\n        \"XGBClassifier With SMOTE\",\n        {use_label_encoder=False,eval_metric='logloss'},\n        XGBClassifier(),\n        (X_train_res,y_train_res),\n        (X_test,y_test)\n    )\n]\n\n# go through all models and create all reports\nreports=[]\nfor model_name,params,model,train_set,test_set in models:\n    X_train=train_set[0]\n    y_train=train_set[1]\n    X_test=test_set[0]\n    y_test=test_set[1]\n    model.set_params(**params)\n    model.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    report=classification_report(y_test,y_pred,output_dict=True)\n    reports.append(report)\n\n# use git/dagshub\nimport dagshub\n# we need envs for connection\nimport os\nos.environ['MLFLOW_TRACKING_USERNAME']=''\nos.environ['MLFLOW_TRACKING_PASSWORD']=''\nos.environ['MLFLOW_TRACKING_URI']=''\ndagshub.init(repo_owner='learnpythonlanguage',repo_name='mlflow_dagshub_demo',mlflow=True)\n# we need to change the url below to deploy to dagshub\n\nmlflow.set_experiment(\"Anomaly Detection\")\nmlflow.set_tracking_url(\"http://127.0.0.1:5000\") # the localhost if MLFlow is run on local\n\nfor i, e in enumerate(models):\n    model_name=e[0],\n    model=e[2],\n    params=e[1],\n    report=reports[i]\n    with mlflow.start_run(run_name=model_name):\n        mlflow.log_params('model_name',model_name)\n        mlflow.log_params(params)\n        mlflow.log_metrics('accuracy',report['accuracy'])\n        mlflow.log_metrics('recall_0',report['0']['recall'])\n        mlflow.log_metrics('recall_1',report['1']['recall'])\n        mlflow.log_metrics('f1_score_macro',report['macro avg']['f1-score'])\n        if \"XGB\" in model_name:\n            mlflow.xgboost.log_model(model,\"model\")\n        else:\n            mlflow.sklearn.log_model(model,\"model\")\n\n# now we can see everything we logged on the MLFlow interface\n# we can see all the metrics and even compare them across different models!","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# register a model\nmodel_name=\"XGB-Smote\"\nrun_id=input(\"Enter run ID:\")\nmodel_uri=f\"runs/{run_id}/{model_name}\"\nresult=mlflow.register_model(\n    model_uri,model_name\n)\n\n# load a model\nmodel_version=1\nmodel_uri_to_load=f\"models:/{model_name}/{model_version}\"\n# we can optionally use a tag like f\"models/{model_name}@challenge\"\nloaded_model=mlflow.xgboost.load_model(model_uri_to_load)\nprint(loaded_model.predict(X_test)[:4])\n\n# transition from d√©v to prod\ndev_model_uri=f\"models:/{model_name}@challenge\"\nprod_model='anomaly-detection-prod'\nclient=mlflow.MLflowClient()\nclient.copy_model_version(src_model_uri=dev_model_uri,dst_name=prod_model)\n\nprod_model_uri=f\"models:/{prod_model}@champion\"\nloaded_model_prod=mlflow.xgboost.load_model(prod_model_uri)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}